https://mp.weixin.qq.com/s?__biz=Mzg2MjEwMjI1Mg==&mid=2247520253&idx=3&sn=604c1efac771c1681f5ab4fe7936d77b&chksm=ce0e387ef979b1686cb45d8e6852d939350a1cdb708bb2e50afd3f97ce9204e00bc9fd2a0545&scene=132#wechat_redirect


好了，总结一下这篇文章的重点。

1、想要提高应用的性能，可以引入「缓存」来解决

2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」

3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生

4、在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案

5、在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性

6、在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率




以mysql为例吧
可以使用阿里的canal将binlog日志采集发送到MQ队列里面然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性

延迟，是因为 mysql 和 redis 主从节点数据同步不是实时的，所以需要等待一段时间，去增强它们的数据一致性。
延时的时间要大于redis写入的时间和redis主从同步的时间，一般是5秒

https://mp.weixin.qq.com/s/Y9S89MT0uAobzRKgYVrI9Q（小吴老师推荐）

先从强一致性，弱一致性，最终一致性说起
要保证一致性，就两步操作，操作数据库，操作缓存
操作数据库就是更新数据库
操作缓存就是更新缓存，删除缓存
更新缓存，比较耗费性能，还有数据一致性的问题，比如缓存结果是经过复杂计算的，或者读少写多的情况
    线程A先发起一个写操作，第一步先更新数据库
    线程B再发起一个写操作，第二步更新了数据库
    由于网络等原因，线程B先更新了缓存
    线程A更新缓存。
    这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据不一致了，脏数据出现啦
所以选删除缓存

然后就是顺序的问题
是先更新数据库，还是先删除缓存
如果先删除缓存
    线程A发起一个写操作，第一步del cache
    此时线程B发起一个读操作，cache miss
    线程B继续读DB，读出来一个老数据
    然后线程B把老数据设置入cache
    线程A写入DB最新的数据
就会有一个执行顺序的问题，导致不一致

所以要先删除缓存，后更新数据库
之后就要保证这两个操作的原子性
    不管是延时双删还是Cache-Aside的先操作数据库再删除缓存，都可能会存在第二步的删除缓存失败，导致的数据不一致问题。
    可以使用这个方案优化：删除失败就多删除几次呀,保证删除缓存成功就可以了呀~ 所以可以引入删除缓存重试机制
    删除缓存重试机制
        写请求更新数据库
        缓存因为某些原因，删除失败
        把删除失败的key放到消息队列
        消费消息队列的消息，获取要删除的key
        重试删除缓存操作
    缺点是会造成好多业务代码入侵

    读取biglog异步删除缓存
        通过数据库的binlog来异步淘汰key。
        以mysql为例吧
        可以使用阿里的canal将binlog日志采集发送到MQ队列里面然后通过ACK机制确认处理这条更新消息，删除缓存，保证数据缓存一致性
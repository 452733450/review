https://mp.weixin.qq.com/s/OwxEdRscZ4luKON1flcuqg
kafka 没有接到消息应该怎么处理？
消息队列主从复制的时候，延迟了，读到从里面是空的，怎么办（我说查数据库二次校验），不能查呢？
消息队列，用到那些mq
积压消息怎么解决的，kafka消费者消费失败了会重复消费吗
mq消息丢失重复消费问题
    丢失
        生产者保证不丢消息
            确保生产的消息能到达存储端。
                如果是RocketMQ消息中间件，Producer生产者提供了三种发送消息的方式，分别是：
                    同步发送
                    异步发送
                    单向发送
                生产者要想发消息时保证消息不丢失，可以：
                    采用同步方式发送，send消息方法返回成功状态，就表示消息正常到达了存储端Broker。
                    如果send消息异常或者返回非成功状态，可以重试。
                    可以使用事务消息，RocketMQ的事务消息机制就是为了保证零丢失来设计的
        存储端不丢消息
            确保消息持久化到磁盘。大家很容易想到就是刷盘机制
                生产者消息发过来时，只有持久化到磁盘，RocketMQ的存储端Broker才返回一个成功的ACK响应，这就是同步刷盘。它保证消息不丢失，但是影响了性能。
                异步刷盘的话，只要消息写入PageCache缓存，就返回一个成功的ACK响应。这样提高了MQ的性能，但是如果这时候机器断电了，就会丢失消息。
                Broker一般是集群部署的，有master主节点和slave从节点。消息到Broker存储端，只有主节点和从节点都写入成功，才反馈成功的ack给生产者。这就是同步复制，它保证了消息不丢失，但是降低了系统的吞吐量。与之对应的就是异步复制，只要消息写入主节点成功，就返回成功的ack，它速度快，但是会有性能问题
        消费者不丢消息
            消费者执行完业务逻辑，再反馈会Broker说消费成功，这样才可以保证消费阶段不丢消息


    重复消费问题
        幂等处理重复消息，简单来说，就是搞个本地表，带唯一业务标记的，利用主键或者唯一性索引，每次处理业务，先校验一下就好啦。又或者用redis缓存下业务标记，每次看下是否处理过了。

        比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
        比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
        比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
        比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

    如何保证消费顺序
        分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；
        或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

kafka和rabbitmq区别，
    单机吞吐量
        万级
        10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景
    时效性
        ms 级
        延迟在 ms 级以内
    可用性
        高，基于主从架构实现高可用
        非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
    消息可靠性
        基本不丢
        经过参数优化配置，可以做到 0 丢失
kafka为啥吞吐量高，
    分布式，分区，多个partition
核心流程
用户在下单时，原先一步提交改为两步走：即提交下单任务+下单任务结果轮询。
提交下单任务：首先，用户在提交下单任务时，需要获得下单许可（PlaceOrderToken），只有获得下单许可的用户才能进行提交下单任务。系统会将下单任务推送到消息队列（RocketMQ）中暂存，然后由订单模块逐个处理消化；
下单任务结果轮询：由于是异步处理，用户在提交下单任务时并不会立即返回结果，所以用户需要按照一定频率来轮询处理结果。

你可能会有疑问，直接把全部请求都丢进消息队列岂不痛快，何必多次一举？这么做当然不是多余，其存在是因为它有好处：
    降低不必要的资源竞争和计算浪费。如果不设置12000的下单许可，则可能有10,000甚至100,0000的用户将请求提交到任务队列，
        但是我们只有区区12000的库存，让那么多人进来图个热闹然后再带走个寂寞？进来了就得招待它们，这会给队列和相关计算方造成巨大压力，
        所以说完全没有必要自找麻烦；
    提升用户体验。在我们前面同步下单的方案中，粗狂的限流会使得大量用户看到“系统繁忙”、“稍后再试”的提示，
        其实他们压根不会有再试的机会，但我们还要用文字骗他们再等等。但是，有了下单许可之后，当许可被抢完的时候，
        我们即可立即向用户展示“售罄”或“暂无库存”等更为友好且贴近事实的提示，不存在忽悠，是真没有库存了；
    确保所有库存都可以卖出。按照1.2或1.5等比例设置高出库存数量的下单许可，就是为了预留一定的Buffer，
        允许一些无效提交但不会影响整体售卖。比如，12000个用户下单申请中，即使有2000个不会下单成功，对系统和用户来说都在预期之内。
        那12000个用户中加入有6000个不下单，岂不是会有4000个卖不出去？当然也不会，我们对此也是有应对的方案。

（一）提交下单任务
在本次异步方案中，提交下单任务是第一步。在设计这一步时，要重点考虑下单许可、重复提交等关键问题的处理，下面的时序图展示了提交下单任务时的完整流程，其主要思想在于：

提交下单任务之前，应通过基础且必要的账号、安全相关的校验；
下单要加锁，防止抖动、连续点击等导致用户层面出现重复提交问题；
所提交的下单任务，应该具有明确且唯一的编码以便于跟踪，即placeOrderTaskId；
当前秒杀活动已经结束时，不应该再允许继续提交；
同一用户、同一秒杀品，不应出现重复提交；
当用户获得提交许可时，应向用户提供placeOrderTaskId用以后续的结果轮询；
当用户未获得提交许可时，应向用户展示“售罄”等明确原因；
下单许可的设计应结合本地缓存+中心化缓存，以降低网络请求负载并提高处理效率；
在处理本地缓存和中心化缓存时，要着重注意过期时间的设置和更新时的锁竞争问题。


下面这段代码可能会让你费解，为何要多次循环调用？其原因在于，系统难免有意外发生（比如扣减时宕机等），
    为了保证可用下单许可数量的有效性，我们给下单许可设置了过期时间，这会导致在执行LUA脚本时数据不存在，
    所以为了应对这种情况，在数据不存在时当前线程会主动尝试刷新数据，然后继续执行LUA脚本。
    也就是说，当用户抢到了下单许可但是下单失败或取消订单时，系统会定时对数据进行纠正，腾出来空余的许可给后面需要的用户，确保所有库存均可对外销售。
    相关的源代码较多，在此就不贴出来了，请读者自行翻阅源码查看。

 private boolean takeOrRecoverToken(PlaceOrderTask placeOrderTask, String script) {
     List < String > keys = new ArrayList < > ();
     keys.add(getItemAvailableTokensKey(placeOrderTask.getItemId()));
     DefaultRedisScript < Long > redisScript = new DefaultRedisScript < > (script, Long.class);

     for (int i = 0; i < 3; i++) {
         Long result = redisCacheService.getRedisTemplate().execute(redisScript, keys);
         if (result == null) {
             return false;
         }
         if (result == -100) {
             refreshLatestAvailableTokens(placeOrderTask.getItemId());
             continue;
         }
         return result == 1 L;
     }
     return false;
 }

（二）异步处理下单任务
通过异步提交到MQ中的订单，MQ会根据订阅将消息推送给订阅方处理。
    对此，RocketMQOrderTaskConsumerService将负责接收订单消息，QueuedPlaceOrderService则是下单处理的核心。
    异步下单处理的流程如下图所示，图中红色区域表示可能的失败场景，最后的绿色箭头表示成功。

    异步处理下单任务时，应先确定TOPIC和订阅关系；
    任务处理结果存储到缓存中，方便客户端轮询；
    任务处理成功后，将订单ID返回给客户端，方便查看订单详情；

可以看到，RocketMQ在接收消息时的方式很简单，我们直接实现RocketMQListener接口。
不过，简单也意味着不够灵活，比如推送过来的消息处理失败时没有稍后重试的机制。


三、压测
在完成异步下单的适配之后，接下来我们来对系统进行压测验收，本次压测主要评估数据完整性和一致性问题，比如是否已全部售罄或是否存在超卖等情况。此外，RocketMQ的表现我们也会关注。

（一） 脚本准备
策略方面，我们选择了瞬时高并发的压测策略，即在瞬间提高系统并发量。
    在配置中，我们配置了100个线程，它们会在5秒之后同时全部启动，在持续60秒之后停止。
    这个策略比较符合秒杀的场景，秒杀中的流量并不是递增而是瞬时跳起，且伴随高并发。

（三）结果分析
1. JMeter压测表现 ✅
压测结束后，打开html格式报告查看压测结果。JMeter压测报告上主要表现的是接口的稳定性和性能，
    比如成功率和RT等，数据一致性问题无法呈现。在报告中，我们可以看到请求数量是4111，并发数是100，错误率是0，
    即所有请求都成功，接口稳定性符合预期。

3.任务id如果存储在本地缓存在集群环境下是否存在问题，过期时间怎么说呢？
    3. 获得任务ID的用户数量有限，不存在高并发，不需要存在本地；

4.异步扣减库存如果不在 redis中，那么用户查看秒杀活动品的时候 如何看到库存的变化呢？
    4. 用户对是否有库存一般不需要强感知，不需要精确看到库存的变化，甚至可以直接模糊为“有货”、“无货”来降低计算成本，保持秒级更新即可

MQ处理订单抛出异常会进行重试,自定义consumer也可以设置重试次数
    @RocketMQMessageListener注解可以指定maxReconsumeTimes为重试次数
    秒杀我觉得其实没必要进行重试，而且RocketMQ重试时间间隔相对秒杀来说有点长

异步下单里：MQ 处理订单过程，是否加入回调操作，效果更佳


1. 分库分表设计
在数据库设计上，我们本次使用了三个库，以实现数据的读写分离和并发写入：

默认主库：存储中以读为主的数据共享数据，比如秒杀活动数据、秒杀品数据以及系统配置等数据；
两个分库：存储以写为主的数据，比如下单数据和库存扣减数据，以分摊数据库的压力。注意，我们这里只用了两个数据库和三个分表，在实际场景中可以根据实际需要灵活设置分库和分表的数量。

2. 分桶设计
分桶的总体设计如下所示。在分库分表的基础上，我们对库存进行分桶存储。
    众所周知，数据库的单行并发写能力极为有限，比如MySQL的单行并发写大概在300~500TPS之间。
    所以，将库存分桶存储可以线性提升并发写入能力。


当我们的写并发量的300以下时，单纯的数据库方案即可胜任；而当写并发量达到1000，数据库+缓存的方案仍然是有效的；
但是当并发量达到数千及更高是，分库分表的库存方案则是势在必行。


队列下单：
	加锁：key是用户id，用户维度
    综合风控校验
	开始队列下单
		获取秒杀品缓存
			先从本地获取，本地获取到了，（获取不到从远程获取）
				比较version，如果请求带过来的version>缓存查出来的当前version
				说明本地缓存已经过期，需要从远程缓存获取最新的缓存
			校验秒杀品是否存在
			秒杀稍后再试
			更新秒杀品最新库存
				获取库存缓存
					先从本地获取
					本地没有的话，从远程获取，获取到了放入本地缓存
					读取远程缓存
						尝试更新秒杀品缓存
							加分布式锁，key为秒杀品id
								加锁不成功则返回稍后再试
								加锁成功，获取缓存
								获取到了，则返回，
								获取不到，从数据库获取
									获取不到则返回noExist
									获取成功设置一个version System.currentTimeMillis()
									存入缓存
		校验是否非在售时间
		生成任务id:用户id，秒杀品id组合之后md5加密
		提交下单任务
			获取taskKey缓存(taskId缓存)，校验是否重复下单(幂等)
			获取可用下单token
				先从redis获取，获取不到则去刷新本地可用token
					// 先从本地缓存获取（秒杀品id为key）
					// 本地没有从远程缓存去拿
							远程如果拿到了，放入本地缓存
					// 远程缓存也没有，则刷新
							加锁，防止并发更新
							获取秒杀品库存，库存的1.5倍作为值存入缓存
			如果可用下单token不存在，或为0，返回暂无可用库存
			执行LUA脚本，库存扣减
				3次for循环扣减
					key不存在，直接返回扣减失败
					没有扣减成功，刷新可用下单token，再来一次扣减
			投递下单任务
				发送消息到RocketMQ(topic为PLACE_ORDER_TASK_TOPIC)
			下单任务提交失败，要恢复token
			把taskId作为key存入缓存；


处理下单消息
	RocketMQOrderTaskConsumerService.onMessage()
		秒杀活动规则校验
			是否存在
			是否上线
			是否在秒杀时段
		秒杀品下单规则校验
		根据秒杀品id从数据库获取秒杀品
		生成订单id(雪花算法)
		数据库扣减库存
		下单
			订单状态为创建
			保存订单
			保存成功，发布领域事件，一般基于独立的消息中间件系统发布
		更新任务状态（更新redis中的taskId）
		订单id存入redis
		如果处理消息发生异常，更新任务id为-1

任务结果轮询
	校验下单任务编号是否错误
	校验任务是否成功
	返回订单id
